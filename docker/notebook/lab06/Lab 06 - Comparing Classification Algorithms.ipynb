{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 06 - Comparing Classification Algorithms\n",
    "\n",
    "The following lab is aimed in developing an intuision for what type of classifiers might work for different datasets. To that end we will explore a variety of simulated datasets and for each test the following classifiers:\n",
    "- **Logistic regression** - aims to model the probability of a sample being classified as $1$ by: $$\\mathbb{P}\\left(y=1\\right) = \\sigma\\left(w^\\top x\\right)$$ where $\\sigma$ denotes the sigmoidal function.\n",
    "- **Decision Tree** - partitions the domain space into a dis-joint union of blocks. Then, prediction is obtained by the block's majoriy vote: $$y = \\sum y_i \\unicode{x1D7D9}\\left[x_i\\in B\\left(x\\right)\\right]$$, where $B\\left(x\\right)$ denotes the block in which the new sample $x$ belongs to.\n",
    "- **$k$-NN classifier** - a model free classifier, predicts label by the \"neighborhood\" of a given sample: $$\\underset{y\\in \\{0,1\\}}{argmax} \\sum_{i=1}^k \\unicode{x1D7D9}\\left[y_{\\pi_{i}} = y\\right]$$ \n",
    "- **SVM classifier** - learns a separating hyperplane, whereby predictions are made according to the samples location in relation to the hyperplane: $$y = sign \\left(w^T \\cdot x + b\\right)$$\n",
    "- **LDA and QDA** - assumes data is generated from different Gaussians. In the case of LDA the covariance matrices of the different Gaussians are identical. In the case of QDA each Gaussian can have a different covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(max_depth=5), \n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    SVC(kernel='linear', probability=True),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()    \n",
    "]\n",
    "\n",
    "model_names = [\"Logistic regression\",\"Desicion Tree (Depth 5)\", \"KNN\", \"Linear SVM\", \"LDA\", \"QDA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data Scenario\n",
    "To load the desired dataset call corresponding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "m = 250\n",
    "symbols = np.array([\"circle\", \"x\"])\n",
    "\n",
    "def triangle():\n",
    "    x = np.random.uniform(low=-5, high=5, size=(m, 2))\n",
    "    return (x, np.array(x[:,0] < x[:,1], dtype=np.int)), \"Linear Separation\"\n",
    "    \n",
    "def circular(radius=9):\n",
    "    x = np.random.uniform(low=-5, high=5, size=(m, 2))\n",
    "    return (x, np.array(x[:,0]**2 + x[:,1]**2 <= radius, dtype=np.int)), \"Circle\"\n",
    "\n",
    "def rectangles():\n",
    "    x = np.random.uniform(low=-5, high=5, size=(m, 2))\n",
    "    return (x, np.array( ((-5 <= x[:,0]) & (x[:,0] <= 0) & (-4 <= x[:,1]) & (x[:, 1] <= 0)) |\n",
    "                         ((1 <= x[:,0])  & (x[:,0] <= 5) & (-1 <= x[:,1]) & (x[:, 1] <= 4)), dtype=np.int)), \\\n",
    "    \"Two Rectangles\"\n",
    "\n",
    "def gaussians(p=.5):\n",
    "    mu, cov = np.array([[-2,-2], [2,1]]), np.array([[[.6, .4], [.4, .6]], [[1.4, -0.9], [-0.9, .6 ]]])\n",
    "    \n",
    "    x, y = [], []\n",
    "    for _ in range(m):\n",
    "        y.append(int(np.random.uniform() <= p))\n",
    "        x.append(np.random.multivariate_normal(mu[y[-1]], cov[y[-1]]))\n",
    "    return (np.array(x), np.array(y)), \"Two Gaussians\"\n",
    "\n",
    "\n",
    "def gaussians_non_linear():\n",
    "    mu = [np.array([-5,-5]), np.array([-5,5]), np.array([5,-5]), np.array([5,5])]\n",
    "    \n",
    "    x, y = [], []\n",
    "    for _m in range(m):\n",
    "        y.append(int(np.random.choice([0,1,2,3])))\n",
    "        x.append(mu[y[-1]] + np.random.multivariate_normal([0,0], [[1,0],[0,1]]))\n",
    "    \n",
    "    y = np.array(y)   \n",
    "    return (np.array(x), np.logical_or(y == 1, y == 2).astype(int)), \"Four Gaussians Two Classes\"\n",
    "\n",
    "def moons():\n",
    "    return make_moons(n_samples=m, noise=0.2, random_state=0), \"Moons\"\n",
    "\n",
    "\n",
    "# To load different datasets replace `triangle()` with one of the other possible datasets\n",
    "(X, y), title = gaussians()\n",
    "lims = np.array([X.min(axis=0), X.max(axis=0)]).T + np.array([-.2, .2])\n",
    "\n",
    "go.Figure(data=[go.Scatter(x=X[:,0], y=X[:,1], mode=\"markers\", showlegend=False,\n",
    "                           marker=dict(color=y, symbol=symbols[y], line=dict(color=\"black\", width=1),\n",
    "                                       colorscale=[custom[0], custom[-1]]))], \n",
    "          layout=go.Layout(title= rf\"$\\text{{(1) {title} Dataset}}$\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=3, subplot_titles=[rf\"$\\text{{{m}}}$\" for m in model_names])\n",
    "for i, m in enumerate(models):\n",
    "    fig.add_traces([decision_surface(m.fit(X, y).predict, lims[0], lims[1], showscale=False),\n",
    "                    go.Scatter(x=X[:,0], y=X[:,1], mode=\"markers\", showlegend=False,\n",
    "                               marker=dict(color=y, symbol=symbols[y], colorscale=[custom[0], custom[-1]], \n",
    "                                           line=dict(color=\"black\", width=1)) )], \n",
    "                   rows=(i//3) + 1, cols=(i%3)+1)\n",
    "\n",
    "fig.update_layout(title=rf\"$\\text{{(2) Decision Boundaries Of Models - {title} Dataset}}$\", margin=dict(t=100))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(layout=go.Layout(title=rf\"$\\text{{(3) ROC Curves Of Models - {title} Dataset}}$\", margin=dict(t=100)))\n",
    "for i, model in enumerate(models):\n",
    "    fpr, tpr, th = metrics.roc_curve(y, model.predict_proba(X)[:, 1])\n",
    "    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=model_names[i]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time To Think...\n",
    "\n",
    "We tried out 6 different models over 3 datasets: A linear separation of $\\mathbb{R}^2$, a circlular dataset and two rectangles. Which learners performed better on each one of the datasets? and what in the manner the learner models the data (that is, in the assumptions regarding the behaviour of the data) made it succeed.\n",
    "\n",
    "- Over the linear separation dataset, the decision tree and $k$NN models were outperformed by the rest of the tested models. \n",
    "- In the case of the circular dataset, no model achieved a perfect classification. The logistic regression, SVM and LDA models have failed over all blue (x's) samples. All three models assume there exists some linear function that separates the two classes, but this is not the case for such dataset. The decision tree and $k$NN classifiers were able to provide a reasonable approximation for the correct decision boundary. The QDA model was also able to provide a good approximation of the correct decision boundary though it under estimated the size of the blue (x's) Gaussian.\n",
    "- Similar to the circular dataset, over the two rectangles dataset only the decision tree, $k$NN and QDA classifiers were able to distinguish between the two classes. Notice that the QDA is not able to capture the correct shape of the decision boundary but only the area in space that is occupied by each class. \n",
    "\n",
    "Next, follow the same process to analyze the results over the Gaussians and Moons datasets.\n",
    "- Though all models managed to correctly classify all samples for the Gaussians dataset, why did the different models produce the different decision boundaries? Why does the decision boundary of the LDA is a straight line and why that of the QDA is oval? \n",
    "- How would it influence each model if we increase the noise of the red (circles) Gaussian in the $y=x$ direction? \n",
    "- How would the decision boundary be influenced if we change the proportion of samples from each class (for example `p=0.2` or `p=0.8`)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
